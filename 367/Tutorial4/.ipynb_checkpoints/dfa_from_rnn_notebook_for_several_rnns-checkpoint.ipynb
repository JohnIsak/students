{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome!\n",
    "\n",
    "This is another notebook demonstration the extraction method from our [ICML 2018 paper](https://arxiv.org/abs/1711.09576), only with a little extra functionality to help you keep track of multiple networks, and without documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dynet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-69c4d007da9b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mLSTM\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLSTMNetwork\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mGRU\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGRUNetwork\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mRNNClassifier\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRNNClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mTraining_Functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmixed_curriculum_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mTomita_Grammars\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtomita_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtomita_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtomita_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtomita_4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtomita_5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtomita_6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtomita_7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Skole\\students\\367\\Tutorial4\\LSTM.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdynet\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mHelper_Functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmap_nested_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mLSTMCell\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#todo: uncouple the linear classifier later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dynet'"
     ]
    }
   ],
   "source": [
    "from LSTM import LSTMNetwork\n",
    "from GRU import GRUNetwork\n",
    "from RNNClassifier import RNNClassifier\n",
    "from Training_Functions import mixed_curriculum_train\n",
    "from Tomita_Grammars import tomita_1, tomita_2, tomita_3, tomita_4, tomita_5, tomita_6, tomita_7\n",
    "from Training_Functions import make_train_set_for_target\n",
    "from Extraction import extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    None == all_my_rnns\n",
    "except NameError:\n",
    "    all_my_rnns = []\n",
    "    \n",
    "class Wrapper:\n",
    "    def __init__(self,rnn,alphabet,target,name,train_set):\n",
    "        self.rnn = rnn\n",
    "        self.alphabet = alphabet\n",
    "        self.target = target\n",
    "        self.name = name\n",
    "        words = sorted(list(train_set.keys()),key=lambda x:len(x))\n",
    "        short_pos = next((w for w in words if target(w)==True),None)\n",
    "        short_neg = next((w for w in words if target(w)==False),None)\n",
    "        self.starting_examples = [w for w in [short_pos,short_neg] if not None==w]\n",
    "        self.train_set = train_set\n",
    "        self.dfas = []\n",
    "    def __repr__(self):\n",
    "        return self.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = \"01\"\n",
    "target = tomita_3\n",
    "name = \"my Tomita 3 RNN\"\n",
    "\n",
    "# alternative option (example):\n",
    "# def target(w):\n",
    "#     if len(w)==0:\n",
    "#         return True\n",
    "#     return w[0]==w[-1]\n",
    "# alphabet = \"abc\"\n",
    "# name = \"start and end same over abc\"\n",
    "\n",
    "\n",
    "rnn = RNNClassifier(alphabet,num_layers=1,hidden_dim=10,RNNClass = LSTMNetwork)\n",
    "\n",
    "\n",
    "train_set = make_train_set_for_target(target,alphabet)\n",
    "wrapper = Wrapper(rnn,alphabet,target,name,train_set)\n",
    "all_my_rnns.append(wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mixed_curriculum_train(wrapper.rnn,wrapper.train_set,stop_threshold = 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wrapper.rnn.renew()  \n",
    "# you only really need this if you start messing about and doing weird stuff. \n",
    "# It cleans the computation graph, but doesn't reset the weights so don't worry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wrapper.dfas.append(\n",
    "    extract(wrapper.rnn,time_limit=50,initial_split_depth=10,starting_examples=wrapper.starting_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = all_my_rnns[-1]\n",
    "wrapper.rnn.renew()\n",
    "dfa_index = -1 # if you want to check the DFA from the last time you extracted something for this network\n",
    "dfa = wrapper.dfas[-1]\n",
    "test_set = wrapper.train_set \n",
    "print(\"testing on train set, i.e. test set is train set\")\n",
    "# here we're printing things on the train set, but you can also try other sets if you like\n",
    "# for instance you could also make one by running make_train_set_for_target(wrapper.target,wrapper.alphabet)\n",
    "\n",
    "\n",
    "from math import pow\n",
    "def percent(num,digits=2):\n",
    "    tens = pow(10,digits)\n",
    "    return str(int(100*num*tens)/tens)+\"%\"\n",
    "\n",
    "dfa.draw_nicely(maximum=30) #max size willing to draw\n",
    "n = len(test_set)\n",
    "print(\"current test set size:\", n)\n",
    "pos = len([w for w in test_set if wrapper.target(w)])\n",
    "print(\"of which positive:\",pos,\"(\"+percent(pos/n)+\")\")\n",
    "rnn_target = len([w for w in test_set if wrapper.rnn.classify_word(w)==wrapper.target(w)])\n",
    "print(\"rnn score against target on test set:\",rnn_target,\"(\"+percent(rnn_target/n)+\")\")\n",
    "dfa_rnn = len([w for w in test_set if wrapper.rnn.classify_word(w)==dfa.classify_word(w)])\n",
    "print(\"extracted dfa score against rnn on test set:\",dfa_rnn,\"(\"+percent(dfa_rnn/n)+\")\")\n",
    "dfa_target = len([w for w in test_set if dfa.classify_word(w)==wrapper.target(w)])\n",
    "print(\"extracted dfa score against target on test set:\",dfa_target,\"(\"+percent(dfa_target/n)+\")\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
