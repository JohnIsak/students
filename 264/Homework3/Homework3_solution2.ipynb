{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - 1): Choosing the right metrics when dealing with unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix random seed for reproducibility:\n",
    "seed = 666\n",
    "# Set up seaborn (for heatmaps):\n",
    "sns.set()\n",
    "\n",
    "### Train and evaluate a K-NN with K=10 on randomly generated binary dataset, with different ratios between the two classes. Use both accuracy and F1 score metrics, plus the confusion matrix:\n",
    "ratios = [0.6, 0.75, 0.9, 0.95, 0.98, 0.99]\n",
    "test_accuracies = []\n",
    "test_f1_scores = []\n",
    "test_confusion_matrices = []\n",
    "for ratio in ratios:\n",
    "    X, Y = make_classification(n_samples=10000, \n",
    "                               n_classes=2, \n",
    "                               n_features=2, \n",
    "                               n_redundant=0, \n",
    "                               n_repeated=0, \n",
    "                               weights=[ratio],\n",
    "                               flip_y=0, \n",
    "                               random_state=seed)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, shuffle=True, random_state=seed)\n",
    "    model = KNeighborsClassifier(n_neighbors=10)\n",
    "    model.fit(X_train, Y_train)\n",
    "    Y_test_pred = model.predict(X_test)\n",
    "\n",
    "    test_accuracy = accuracy_score(Y_test, Y_test_pred)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    test_f1_score = f1_score(Y_test, Y_test_pred, pos_label=1)\n",
    "    test_f1_scores.append(test_f1_score)\n",
    "\n",
    "    test_confusion_matrix = confusion_matrix(Y_test, Y_test_pred)\n",
    "    test_confusion_matrices.append(test_confusion_matrix)\n",
    "\n",
    "for test_confusion_matrix, ratio, idx in zip(test_confusion_matrices, ratios, range(len(ratios))):\n",
    "    plt.figure(1, figsize=(15, 12))\n",
    "    plt.subplot(3, 3, idx+1)\n",
    "    plt.title(\"Confusion matrix, 1st class ratio = \" + str(ratio))\n",
    "    sns.heatmap(data=test_confusion_matrix.round(2), annot=True, fmt='d', cmap=sns.color_palette(\"RdBu_r\", 1000))\n",
    "plt.figure(1)\n",
    "plt.suptitle(\"Assessment of a K-NN model (K=10) on randomly generated binary datasets, with different ratios between the two classes\")\n",
    "plt.subplot(3, 3, 8)\n",
    "plt.title(\"Test accuracies + test F1-scores of minority class as functions of the 1st class ratio\")\n",
    "plt.plot(ratios, test_accuracies, c='g')\n",
    "plt.plot(ratios, test_f1_scores, c='r')\n",
    "plt.legend([\"Accuracy\", \"F1-score\"], loc='best')\n",
    "plt.xlabel('1st class ratio')\n",
    "plt.ylabel('Quality measures')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us focus on the confusion matrices first. With a binary dataset, the confusion matrix contains the true negatives in the upper-left square, the false positives in the upper-right square, the false negatives in the bottom-left square and the true positives in the bottom-right square, where the \"positive\" class is attributed to the minority class. Equivalently, the rows of the confusion matrix represent the actual class of each sample whereas the columns represent their predicted class.\n",
    "\n",
    "Now if we look at the different confusion matrices, we notice that when data is balanced, there is a symmetry between the true positives and the true negatives, and the same can be said about the false positives with respect to the false negatives. But the more unbalanced the data, the more the symmetry collapses in the confusion matrix: true negatives (the correctly classified samples from the dominant class) converge to the total amount of samples, false positives converge to 0 and true positives are less and less prevalent until there are more false negatives than there are true positives. This shows that for the very unbalanced datasets, our $K$-NN model totally failed to capture the underlying structure of the minority class. \n",
    "\n",
    "If we consider the accuracy metric, it only captured the information that true negatives massively dominate all other categories in the presence of important data imbalance, which makes for an overall increasing accuracy as the imbalance in the data rises. In other word, the accuracy metric is not suitable to correctly assess the performance of a model when the data is unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - 2): Model selection with Kfold cross-validation for classification on unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split+shuffle X and Y into k=num_folds different folds:\n",
    "def KFold_split(X, Y, num_folds, seed):\n",
    "    KFold_splitter = KFold(n_splits=num_folds, shuffle=True, random_state=seed)\n",
    "    X_train_folds = []\n",
    "    X_val_folds = []\n",
    "    Y_train_folds = []\n",
    "    Y_val_folds = []\n",
    "    for (kth_fold_train_idxs, kth_fold_val_idxs) in KFold_splitter.split(X, Y):\n",
    "        X_train_folds.append(X[kth_fold_train_idxs])\n",
    "        X_val_folds.append(X[kth_fold_val_idxs])\n",
    "        Y_train_folds.append(Y[kth_fold_train_idxs])\n",
    "        Y_val_folds.append(Y[kth_fold_val_idxs])\n",
    "    return X_train_folds, X_val_folds, Y_train_folds, Y_val_folds\n",
    "\n",
    "### Select a model via Kfold cross-validation:\n",
    "def KFold_model_selection(X, Y, models, num_folds, seed):\n",
    "    # Extract a test set:\n",
    "    X_train_val, X_test, Y_train_val, Y_test = train_test_split(X, Y, test_size=0.3, shuffle=True, random_state=seed)\n",
    "    # Extract train and validation folds:\n",
    "    X_train_folds, X_val_folds, Y_train_folds, Y_val_folds = KFold_split(X_train_val, Y_train_val, num_folds, seed)\n",
    "    # For each model, do KFold cross validation:\n",
    "    mean_val_F1_scores = []\n",
    "    for key in models.keys():\n",
    "        print(\"\\nNow preprocessing model\", models[key])\n",
    "        mean_val_F1_score = perform_KFold_CV(X_train_folds, X_val_folds, Y_train_folds, Y_val_folds, model_idx=key)\n",
    "        print(\"Mean validation F1 score:\", mean_val_F1_score)\n",
    "        mean_val_F1_scores.append(mean_val_F1_score)\n",
    "    # The model with the highest mean validation F1 score is our model of choice:\n",
    "    best_model_idx = np.argmax(np.array(mean_val_F1_scores))\n",
    "    best_model = models[best_model_idx]\n",
    "    print(\"\\n\\nBest model:\", best_model)\n",
    "    # Train the best model on the whole train set then evaluate it on the test set:\n",
    "    best_model_test_F1_score, best_model_test_confusion_matrix = assess_model(X_train=X_train_val, \n",
    "                                                                              X_eval=X_test,\n",
    "                                                                              Y_train=Y_train_val,\n",
    "                                                                              Y_eval=Y_test,\n",
    "                                                                              model_idx=best_model_idx)\n",
    "    print(\"Test F1 score:\", best_model_test_F1_score)\n",
    "    plt.figure(2, figsize=(7, 5))\n",
    "    plt.title(\"Test confusion matrix of the best model \" + best_model)\n",
    "    sns.heatmap(data=best_model_test_confusion_matrix.round(2), annot=True, fmt='d', cmap=sns.color_palette(\"RdBu_r\", 1000))\n",
    "    plt.show()\n",
    "\n",
    "### KFold cross-validation of a model:\n",
    "def perform_KFold_CV(X_train_folds, X_val_folds, Y_train_folds, Y_val_folds, model_idx):\n",
    "    val_fold_F1_scores = []\n",
    "    # For each fold, assess a surrogate model:\n",
    "    cmpt = 0\n",
    "    for X_train_fold, X_val_fold, Y_train_fold, Y_val_fold in zip(X_train_folds, X_val_folds, Y_train_folds, Y_val_folds):\n",
    "        val_fold_F1_score, _ = assess_model(X_train=X_train_fold, \n",
    "                                            X_eval=X_val_fold,\n",
    "                                            Y_train=Y_train_fold,\n",
    "                                            Y_eval=Y_val_fold,\n",
    "                                            model_idx=model_idx)\n",
    "        cmpt += 1\n",
    "        print(\"Surrogate model\", str(cmpt) + \"/\" + str(len(X_val_folds)), \"validation F1 score:\", val_fold_F1_score)\n",
    "        val_fold_F1_scores.append(val_fold_F1_score)\n",
    "    # Compute the mean validation F1 score between all the folds:\n",
    "    mean_val_F1_score = np.mean(np.array(val_fold_F1_scores))\n",
    "    return mean_val_F1_score\n",
    "\n",
    "### Fit and evaluate a model:\n",
    "def assess_model(X_train, X_eval, Y_train, Y_eval, model_idx):\n",
    "    # Build the model:\n",
    "    if model_idx == 0:\n",
    "        model = KNeighborsClassifier(n_neighbors=20)\n",
    "    elif model_idx == 1:\n",
    "        model = LogisticRegression(solver='lbfgs')\n",
    "    elif model_idx == 2:\n",
    "        model = DecisionTreeClassifier()\n",
    "    # Fit the model:\n",
    "    model.fit(X_train, Y_train)\n",
    "    # Evaluate the model on the evaluation set:\n",
    "    Y_eval_pred = model.predict(X_eval)\n",
    "    eval_F1_score = f1_score(Y_eval, Y_eval_pred, pos_label=1)\n",
    "    eval_confusion_matrix = confusion_matrix(Y_eval, Y_eval_pred)\n",
    "    return eval_F1_score, eval_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model selection of a classification model on unbalanced data with KFold cross-validation:\n",
    "# Load an unbalanced binary dataset:\n",
    "with open('custom_unbalanced_dataset.pickle', 'rb') as unbalanced_dataset:\n",
    "    X, Y = pickle.load(unbalanced_dataset)\n",
    "    # Models to be cross-validated:\n",
    "    models = {0: \"K-NN, K=20\",\n",
    "              1: \"Logistic regression\",\n",
    "              2: \"Decision Tree\"}\n",
    "    # Select model with KFold cross-validation (use 10 folds):\n",
    "    KFold_model_selection(X, Y, models, num_folds=10, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform cross-validation, we can choose the F1-score metric, which takes into account precision and recall. Precision is the ratio of true positives among the true positives and the false positives. Recall is the ratio of true positives among the true positives and the false negatives. In the $K$-NN example above, we can see that this metric reduces significantly as the imbalance in the data increases, so it is more suitable than the accuracy metric in our case, since we are dealing once again with a very unbalanced dataset (unbalance ratio of 0.9/0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
